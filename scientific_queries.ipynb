{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Queries for CDM Ontology Data\n",
    "\n",
    "This notebook contains scientifically relevant queries for exploring the CDM ontology and genomic data.\n",
    "\n",
    "**Data Overview:**\n",
    "- `statements`: 42.4M ontology statements (RDF triples)\n",
    "- `entailed_edge`: 117.5M inferred relationships\n",
    "- `feature_annotation`: 237K genomic features from 50 E. coli genomes\n",
    "- `term_association`: 3.3K enzyme-reaction mappings\n",
    "\n",
    "**Note**: Run these queries on your remote JupyterHub for full dataset. This notebook includes both Spark and pandas versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# For remote execution with Spark\nfrom spark.utils import get_spark_session\nimport time\nspark = get_spark_session()\n\n# Set the namespace\nnamespace = 'ontology_data'\n\n# Helper function to time queries\ndef time_query(query_name, query_func):\n    \"\"\"Execute a query and print execution time\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"Executing: {query_name}\")\n    print(f\"{'='*60}\")\n    start_time = time.time()\n    result = query_func()\n    end_time = time.time()\n    execution_time = end_time - start_time\n    print(f\"\\nQuery execution time: {execution_time:.2f} seconds\")\n    return result"
  },
  {
   "cell_type": "markdown",
   "source": "## 0. Genome Feature to Reaction Mapping\n\nMap genomic features to their associated SEED reactions through RAST role annotations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Query 0: Map E. coli genome features to SEED reactions via RAST roles\ndef query_genome_reactions():\n    query = f\"\"\"\n    WITH genome_features AS (\n        -- Get all features for genome 562.61239 with RAST annotations\n        SELECT \n            f.genome_id,\n            f.feature_id,\n            f.rast\n        FROM {namespace}.feature_annotation f\n        WHERE f.genome_id = '562.61239'\n        AND f.rast IS NOT NULL\n    ),\n    feature_reactions AS (\n        -- Map RAST roles to SEED reactions through term_association\n        SELECT DISTINCT\n            gf.genome_id,\n            gf.feature_id,\n            gf.rast,\n            ta.object as seed_reaction\n        FROM genome_features gf\n        INNER JOIN {namespace}.term_association ta\n            ON gf.rast = ta.subject\n        WHERE ta.object LIKE 'seed.reaction:%'\n    ),\n    reaction_names AS (\n        -- Get reaction names from statements table\n        SELECT \n            subject as reaction_id,\n            value as reaction_name\n        FROM {namespace}.statements\n        WHERE predicate = 'rdfs:label'\n        AND subject LIKE 'seed.reaction:%'\n    )\n    SELECT \n        fr.genome_id,\n        fr.feature_id,\n        fr.rast,\n        fr.seed_reaction,\n        rn.reaction_name\n    FROM feature_reactions fr\n    LEFT JOIN reaction_names rn ON fr.seed_reaction = rn.reaction_id\n    ORDER BY fr.genome_id, fr.feature_id\n    LIMIT 100\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    display(df.head(20))\n    print(f\"\\\\nTotal features with reaction mappings: {len(df)}\")\n    return df\n\n# Execute the query with timing\ntime_query(\"Genome Feature to Reaction Mapping\", query_genome_reactions)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Metabolic Pathway Analysis\n",
    "\n",
    "Find all biochemical reactions associated with E. coli enzymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 1.1: Find all EC numbers in E. coli genomes and their associated reactions\ndef query_ec_reactions():\n    query = f\"\"\"\n    WITH ec_numbers AS (\n        SELECT DISTINCT \n            bakta_ec as ec_number,\n            COUNT(DISTINCT genome_id) as genome_count,\n            COUNT(*) as feature_count\n        FROM {namespace}.feature_annotation\n        WHERE bakta_ec IS NOT NULL\n        GROUP BY bakta_ec\n    ),\n    ec_reactions AS (\n        SELECT \n            s.subject as ec_id,\n            s.object as reaction_id,\n            s.predicate\n        FROM {namespace}.statements s\n        WHERE s.subject LIKE 'EC:%'\n        AND s.predicate IN ('skos:exactMatch', 'oio:hasDbXref')\n        AND s.object LIKE 'RHEA:%'\n    )\n    SELECT \n        e.ec_number,\n        e.genome_count,\n        e.feature_count,\n        r.reaction_id,\n        r.predicate\n    FROM ec_numbers e\n    LEFT JOIN ec_reactions r ON CONCAT('EC:', e.ec_number) = r.ec_id\n    ORDER BY e.genome_count DESC, e.feature_count DESC\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query).show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"EC Numbers and RHEA Reactions\", query_ec_reactions)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 1.2: Find metabolic subsystems through ModelSEED roles\ndef query_subsystems():\n    query = f\"\"\"\n    WITH seed_roles AS (\n        SELECT DISTINCT\n            subject as role_id,\n            object as reaction_id\n        FROM {namespace}.term_association\n        WHERE predicate = 'RO:0002327'  -- enables\n    ),\n    role_names AS (\n        SELECT \n            subject,\n            value as role_name\n        FROM {namespace}.statements\n        WHERE subject LIKE 'seed.role:%'\n        AND predicate = 'rdfs:label'\n    ),\n    reaction_names AS (\n        SELECT \n            subject,\n            value as reaction_name\n        FROM {namespace}.statements\n        WHERE subject LIKE 'seed.reaction:%'\n        AND predicate = 'rdfs:label'\n    )\n    SELECT \n        r.role_id,\n        rn.role_name,\n        r.reaction_id,\n        rxn.reaction_name,\n        COUNT(*) OVER (PARTITION BY r.role_id) as reactions_per_role\n    FROM seed_roles r\n    LEFT JOIN role_names rn ON r.role_id = rn.subject\n    LEFT JOIN reaction_names rxn ON r.reaction_id = rxn.subject\n    ORDER BY reactions_per_role DESC, r.role_id\n    LIMIT 30\n    \"\"\"\n    \n    df = spark.sql(query).show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"ModelSEED Roles and Reactions\", query_subsystems)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Taxonomic Distribution Analysis\n",
    "\n",
    "Analyze the distribution of metabolic capabilities across taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 2.1: E. coli strain diversity analysis\ndef query_strain_diversity():\n    query = f\"\"\"\n    WITH strain_features AS (\n        SELECT \n            genome_id,\n            genome_taxa,\n            COUNT(DISTINCT feature_id) as total_features,\n            COUNT(DISTINCT bakta_ec) as unique_ec_numbers,\n            COUNT(DISTINCT bakta_go) as unique_go_terms,\n            COUNT(DISTINCT bakta_cog_id) as unique_cog_categories,\n            SUM(CASE WHEN bakta_ec IS NOT NULL THEN 1 ELSE 0 END) as features_with_ec,\n            SUM(CASE WHEN bakta_go IS NOT NULL THEN 1 ELSE 0 END) as features_with_go\n        FROM {namespace}.feature_annotation\n        GROUP BY genome_id, genome_taxa\n    ),\n    taxa_labels AS (\n        SELECT \n            subject,\n            value as organism_name\n        FROM {namespace}.statements\n        WHERE predicate = 'rdfs:label'\n        AND subject LIKE 'NCBITaxon:%'\n    )\n    SELECT \n        s.*,\n        t.organism_name,\n        ROUND(s.features_with_ec * 100.0 / s.total_features, 2) as pct_with_ec,\n        ROUND(s.features_with_go * 100.0 / s.total_features, 2) as pct_with_go\n    FROM strain_features s\n    LEFT JOIN taxa_labels t ON s.genome_taxa = t.subject\n    ORDER BY s.unique_ec_numbers DESC\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"E. coli Strain Functional Diversity\", query_strain_diversity)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 2.2: Taxonomic hierarchy exploration\ndef query_taxonomy():\n    query = f\"\"\"\n    WITH ecoli_taxa AS (\n        SELECT DISTINCT genome_taxa \n        FROM {namespace}.feature_annotation\n    ),\n    taxonomic_hierarchy AS (\n        SELECT \n            e.subject,\n            e.object as parent_taxon,\n            s1.value as subject_name,\n            s2.value as parent_name\n        FROM {namespace}.entailed_edge e\n        INNER JOIN ecoli_taxa t ON e.subject = t.genome_taxa\n        LEFT JOIN {namespace}.statements s1 \n            ON e.subject = s1.subject AND s1.predicate = 'rdfs:label'\n        LEFT JOIN {namespace}.statements s2 \n            ON e.object = s2.subject AND s2.predicate = 'rdfs:label'\n        WHERE e.predicate = 'rdfs:subClassOf'\n        AND e.object LIKE 'NCBITaxon:%'\n    )\n    SELECT * FROM taxonomic_hierarchy\n    WHERE parent_name IS NOT NULL\n    ORDER BY subject\n    LIMIT 50\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"Taxonomic Hierarchy for E. coli Strains\", query_taxonomy)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chemical Transformation Networks\n",
    "\n",
    "Analyze biochemical reactions and compound transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 3.1: Find metabolic reactions with their substrates and products\ndef query_reactions():\n    query = f\"\"\"\n    WITH rhea_reactions AS (\n        SELECT DISTINCT\n            subject as reaction_id,\n            value as reaction_name\n        FROM {namespace}.statements\n        WHERE subject LIKE 'RHEA:%'\n        AND predicate = 'rdfs:label'\n    ),\n    reaction_participants AS (\n        SELECT \n            e.subject as reaction_id,\n            e.object as compound_id,\n            e.predicate as role\n        FROM {namespace}.entailed_edge e\n        WHERE e.subject LIKE 'RHEA:%'\n        AND e.object LIKE 'CHEBI:%'\n        AND e.predicate IN ('RO:0000057', 'BFO:0000051')  -- has participant, has part\n    ),\n    compound_names AS (\n        SELECT \n            subject as compound_id,\n            value as compound_name\n        FROM {namespace}.statements\n        WHERE subject LIKE 'CHEBI:%'\n        AND predicate = 'rdfs:label'\n    )\n    SELECT \n        r.reaction_id,\n        r.reaction_name,\n        p.compound_id,\n        c.compound_name,\n        p.role\n    FROM rhea_reactions r\n    JOIN reaction_participants p ON r.reaction_id = p.reaction_id\n    LEFT JOIN compound_names c ON p.compound_id = c.compound_id\n    WHERE r.reaction_name IS NOT NULL\n    ORDER BY r.reaction_id, p.role\n    LIMIT 50\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"RHEA Reactions and Chemical Participants\", query_reactions)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 3.2: ModelSEED compound analysis\ndef query_seed_compounds():\n    query = f\"\"\"\n    WITH seed_compounds AS (\n        SELECT \n            subject as compound_id,\n            value as compound_name\n        FROM {namespace}.statements\n        WHERE subject LIKE 'seed.compound:%'\n        AND predicate = 'rdfs:label'\n    ),\n    compound_xrefs AS (\n        SELECT \n            subject as compound_id,\n            object as external_id\n        FROM {namespace}.statements\n        WHERE subject LIKE 'seed.compound:%'\n        AND predicate IN ('oio:hasDbXref', 'skos:exactMatch')\n        AND (object LIKE 'CHEBI:%' OR object LIKE 'KEGG:%')\n    )\n    SELECT \n        c.compound_id,\n        c.compound_name,\n        x.external_id,\n        COUNT(*) OVER (PARTITION BY c.compound_id) as xref_count\n    FROM seed_compounds c\n    LEFT JOIN compound_xrefs x ON c.compound_id = x.compound_id\n    ORDER BY xref_count DESC, c.compound_id\n    LIMIT 30\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"ModelSEED Compounds and Cross-References\", query_seed_compounds)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Functional Annotation Analysis\n",
    "\n",
    "Analyze GO terms and functional categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4.1: GO term enrichment across genomes\n",
    "query_go_enrichment = f\"\"\"\n",
    "WITH go_counts AS (\n",
    "    SELECT \n",
    "        bakta_go as go_term,\n",
    "        COUNT(DISTINCT genome_id) as genome_count,\n",
    "        COUNT(*) as annotation_count\n",
    "    FROM {namespace}.feature_annotation\n",
    "    WHERE bakta_go IS NOT NULL\n",
    "    GROUP BY bakta_go\n",
    "),\n",
    "go_labels AS (\n",
    "    SELECT \n",
    "        subject as go_id,\n",
    "        value as go_name\n",
    "    FROM {namespace}.statements\n",
    "    WHERE subject LIKE 'GO:%'\n",
    "    AND predicate = 'rdfs:label'\n",
    "),\n",
    "go_definitions AS (\n",
    "    SELECT \n",
    "        subject as go_id,\n",
    "        value as go_definition\n",
    "    FROM {namespace}.statements\n",
    "    WHERE subject LIKE 'GO:%'\n",
    "    AND predicate = 'oio:hasDefinition'\n",
    ")\n",
    "SELECT \n",
    "    g.go_term,\n",
    "    l.go_name,\n",
    "    d.go_definition,\n",
    "    g.genome_count,\n",
    "    g.annotation_count,\n",
    "    ROUND(g.genome_count * 100.0 / 50, 2) as pct_genomes  -- 50 total genomes\n",
    "FROM go_counts g\n",
    "LEFT JOIN go_labels l ON g.go_term = l.go_id\n",
    "LEFT JOIN go_definitions d ON g.go_term = d.go_id\n",
    "ORDER BY g.genome_count DESC, g.annotation_count DESC\n",
    "LIMIT 25\n",
    "\"\"\"\n",
    "\n",
    "print(\"Most common GO terms across E. coli genomes:\")\n",
    "spark.sql(query_go_enrichment).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4.2: EC to GO mapping through shared functions\n",
    "query_ec_go_mapping = f\"\"\"\n",
    "WITH ec_go_features AS (\n",
    "    SELECT \n",
    "        bakta_ec as ec_number,\n",
    "        bakta_go as go_term,\n",
    "        COUNT(*) as co_occurrence_count\n",
    "    FROM {namespace}.feature_annotation\n",
    "    WHERE bakta_ec IS NOT NULL \n",
    "    AND bakta_go IS NOT NULL\n",
    "    GROUP BY bakta_ec, bakta_go\n",
    "),\n",
    "ec_labels AS (\n",
    "    SELECT \n",
    "        subject,\n",
    "        value as ec_name\n",
    "    FROM {namespace}.statements\n",
    "    WHERE subject LIKE 'EC:%'\n",
    "    AND predicate = 'rdfs:label'\n",
    "),\n",
    "go_labels AS (\n",
    "    SELECT \n",
    "        subject,\n",
    "        value as go_name\n",
    "    FROM {namespace}.statements\n",
    "    WHERE subject LIKE 'GO:%'\n",
    "    AND predicate = 'rdfs:label'\n",
    ")\n",
    "SELECT \n",
    "    f.ec_number,\n",
    "    e.ec_name,\n",
    "    f.go_term,\n",
    "    g.go_name,\n",
    "    f.co_occurrence_count\n",
    "FROM ec_go_features f\n",
    "LEFT JOIN ec_labels e ON CONCAT('EC:', f.ec_number) = e.subject\n",
    "LEFT JOIN go_labels g ON f.go_term = g.subject\n",
    "WHERE f.co_occurrence_count > 5\n",
    "ORDER BY f.co_occurrence_count DESC\n",
    "LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "print(\"EC number to GO term co-occurrence mapping:\")\n",
    "spark.sql(query_ec_go_mapping).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Protein Family and Domain Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 5.1: InterPro domain distribution\ndef query_interpro():\n    query = f\"\"\"\n    WITH interpro_counts AS (\n        SELECT \n            bakta_interpro as interpro_id,\n            COUNT(DISTINCT genome_id) as genome_count,\n            COUNT(DISTINCT protein_hash) as unique_proteins,\n            COUNT(*) as total_occurrences\n        FROM {namespace}.feature_annotation\n        WHERE bakta_interpro IS NOT NULL\n        GROUP BY bakta_interpro\n    ),\n    interpro_info AS (\n        SELECT \n            subject,\n            value as interpro_name\n        FROM {namespace}.statements\n        WHERE subject LIKE 'IPR%'\n        AND predicate = 'rdfs:label'\n    )\n    SELECT \n        i.interpro_id,\n        info.interpro_name,\n        i.genome_count,\n        i.unique_proteins,\n        i.total_occurrences,\n        ROUND(i.total_occurrences * 1.0 / i.unique_proteins, 2) as avg_copies_per_protein\n    FROM interpro_counts i\n    LEFT JOIN interpro_info info ON i.interpro_id = info.subject\n    ORDER BY i.genome_count DESC, i.total_occurrences DESC\n    LIMIT 30\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"InterPro Domain Distribution\", query_interpro)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 5.2: UniRef cluster analysis\ndef query_uniref():\n    query = f\"\"\"\n    SELECT \n        bakta_uniref as uniref_cluster,\n        COUNT(DISTINCT genome_id) as genome_count,\n        COUNT(DISTINCT protein_hash) as unique_sequences,\n        COUNT(*) as total_genes,\n        COLLECT_SET(bakta_gene)[0] as example_gene_name,\n        COLLECT_SET(bakta_product)[0] as example_product\n    FROM {namespace}.feature_annotation\n    WHERE bakta_uniref IS NOT NULL\n    GROUP BY bakta_uniref\n    HAVING genome_count = 50  -- Core genes present in all genomes\n    ORDER BY total_genes DESC\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"Core Genes (UniRef Clusters)\", query_uniref)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complex Network Queries\n",
    "\n",
    "Advanced queries combining multiple data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 6.1: Complete metabolic pathway reconstruction\ndef query_pathway():\n    query = f\"\"\"\n    WITH enzyme_reactions AS (\n        -- Get EC numbers from genomes and their reactions\n        SELECT DISTINCT\n            f.bakta_ec as ec_number,\n            f.genome_id,\n            ta.object as reaction_id\n        FROM {namespace}.feature_annotation f\n        JOIN {namespace}.statements s \n            ON CONCAT('EC:', f.bakta_ec) = s.subject\n        JOIN {namespace}.term_association ta\n            ON s.object = ta.subject\n        WHERE f.bakta_ec IS NOT NULL\n        AND s.predicate = 'skos:exactMatch'\n        AND ta.predicate = 'RO:0002327'\n    ),\n    reaction_compounds AS (\n        -- Get compounds involved in reactions\n        SELECT \n            e.subject as reaction_id,\n            e.object as compound_id,\n            s.value as compound_name\n        FROM {namespace}.entailed_edge e\n        JOIN {namespace}.statements s\n            ON e.object = s.subject AND s.predicate = 'rdfs:label'\n        WHERE e.subject LIKE 'seed.reaction:%'\n        AND e.object LIKE 'seed.compound:%'\n        AND e.predicate = 'RO:0000057'  -- has participant\n    )\n    SELECT \n        er.genome_id,\n        er.ec_number,\n        er.reaction_id,\n        rc.compound_id,\n        rc.compound_name\n    FROM enzyme_reactions er\n    JOIN reaction_compounds rc ON er.reaction_id = rc.reaction_id\n    WHERE rc.compound_name LIKE '%glucose%' OR rc.compound_name LIKE '%pyruvate%'\n    ORDER BY er.genome_id, er.reaction_id\n    LIMIT 50\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"Metabolic Pathway Reconstruction - Glucose/Pyruvate\", query_pathway)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query 6.2: Functional comparison between strains\ndef query_strain_comparison():\n    query = f\"\"\"\n    WITH genome_functions AS (\n        SELECT \n            genome_id,\n            genome_taxa,\n            COLLECT_SET(bakta_ec) as ec_set,\n            COLLECT_SET(bakta_go) as go_set,\n            COLLECT_SET(bakta_cog_category) as cog_set\n        FROM {namespace}.feature_annotation\n        GROUP BY genome_id, genome_taxa\n    ),\n    genome_pairs AS (\n        SELECT \n            g1.genome_id as genome1,\n            g2.genome_id as genome2,\n            SIZE(array_intersect(g1.ec_set, g2.ec_set)) as shared_ec,\n            SIZE(g1.ec_set) as ec_count1,\n            SIZE(g2.ec_set) as ec_count2,\n            SIZE(array_intersect(g1.go_set, g2.go_set)) as shared_go,\n            SIZE(g1.go_set) as go_count1,\n            SIZE(g2.go_set) as go_count2\n        FROM genome_functions g1\n        CROSS JOIN genome_functions g2\n        WHERE g1.genome_id < g2.genome_id\n    )\n    SELECT \n        genome1,\n        genome2,\n        shared_ec,\n        ROUND(shared_ec * 200.0 / (ec_count1 + ec_count2), 2) as ec_similarity_pct,\n        shared_go,\n        ROUND(shared_go * 200.0 / (go_count1 + go_count2), 2) as go_similarity_pct\n    FROM genome_pairs\n    ORDER BY ec_similarity_pct DESC\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"Functional Similarity Between E. coli Strains\", query_strain_comparison)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Export Queries\n",
    "\n",
    "Queries to export specific datasets for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export query 1: Create a gene-to-function mapping table\ndef export_gene_functions():\n    query = f\"\"\"\n    SELECT \n        feature_id,\n        genome_id,\n        bakta_gene as gene_name,\n        bakta_product as product,\n        bakta_ec as ec_number,\n        bakta_go as go_term,\n        bakta_cog_id as cog_id,\n        bakta_cog_category as cog_category,\n        bakta_interpro as interpro_domain,\n        bakta_uniref as uniref_cluster,\n        protein_hash\n    FROM {namespace}.feature_annotation\n    WHERE bakta_ec IS NOT NULL OR bakta_go IS NOT NULL\n    ORDER BY genome_id, feature_id\n    \"\"\"\n    \n    df = spark.sql(query)\n    # Uncomment to save:\n    # df.coalesce(1).write.mode('overwrite').option('header', 'true').csv('gene_functions_export')\n    print(f\"Export query would return {df.count()} rows\")\n    return df\n\n# Execute the query with timing\ntime_query(\"Gene Function Export Query\", export_gene_functions)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export query 2: Create reaction network for visualization\ndef export_reaction_network():\n    query = f\"\"\"\n    WITH reaction_edges AS (\n        SELECT DISTINCT\n            r1.object as compound,\n            r1.subject as reaction1,\n            r2.subject as reaction2\n        FROM {namespace}.entailed_edge r1\n        JOIN {namespace}.entailed_edge r2\n            ON r1.object = r2.object\n        WHERE r1.subject LIKE 'seed.reaction:%'\n        AND r2.subject LIKE 'seed.reaction:%'\n        AND r1.subject < r2.subject\n        AND r1.predicate = 'RO:0000057'\n        AND r2.predicate = 'RO:0000057'\n    ),\n    compound_names AS (\n        SELECT subject, value as name\n        FROM {namespace}.statements\n        WHERE predicate = 'rdfs:label'\n        AND subject LIKE 'seed.compound:%'\n    )\n    SELECT \n        e.reaction1,\n        e.reaction2,\n        e.compound,\n        c.name as compound_name,\n        COUNT(*) as shared_compounds\n    FROM reaction_edges e\n    LEFT JOIN compound_names c ON e.compound = c.subject\n    GROUP BY e.reaction1, e.reaction2, e.compound, c.name\n    ORDER BY shared_compounds DESC\n    LIMIT 1000\n    \"\"\"\n    \n    df = spark.sql(query)\n    print(f\"Reaction network export would contain {df.count()} edges\")\n    return df\n\n# Execute the query with timing\ntime_query(\"Reaction Network Export Query\", export_reaction_network)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate summary statistics\ndef query_summary_stats():\n    query = f\"\"\"\n    WITH stats AS (\n        SELECT \n            'Total genomes' as metric,\n            COUNT(DISTINCT genome_id) as value\n        FROM {namespace}.feature_annotation\n        UNION ALL\n        SELECT \n            'Total features' as metric,\n            COUNT(*) as value\n        FROM {namespace}.feature_annotation\n        UNION ALL\n        SELECT \n            'Features with EC numbers' as metric,\n            COUNT(*) as value\n        FROM {namespace}.feature_annotation\n        WHERE bakta_ec IS NOT NULL\n        UNION ALL\n        SELECT \n            'Features with GO terms' as metric,\n            COUNT(*) as value\n        FROM {namespace}.feature_annotation\n        WHERE bakta_go IS NOT NULL\n        UNION ALL\n        SELECT \n            'Unique EC numbers' as metric,\n            COUNT(DISTINCT bakta_ec) as value\n        FROM {namespace}.feature_annotation\n        UNION ALL\n        SELECT \n            'Unique GO terms' as metric,\n            COUNT(DISTINCT bakta_go) as value\n        FROM {namespace}.feature_annotation\n        UNION ALL\n        SELECT \n            'Total statements' as metric,\n            COUNT(*) as value\n        FROM {namespace}.statements\n        UNION ALL\n        SELECT \n            'Total entailed edges' as metric,\n            COUNT(*) as value\n        FROM {namespace}.entailed_edge\n    )\n    SELECT * FROM stats\n    ORDER BY metric\n    \"\"\"\n    \n    df = spark.sql(query)\n    df.show(truncate=False)\n    return df\n\n# Execute the query with timing\ntime_query(\"Dataset Summary Statistics\", query_summary_stats)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}