{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook - July 10th\n",
    "\n",
    "This notebook demonstrates the building blocks that lead to Query 0 (Genome Feature to Reaction Mapping) and explores comparative genomics across 50 E. coli strains.\n",
    "\n",
    "## Part 1: Building Blocks for Query 0\n",
    "\n",
    "Let's explore each component that makes the genome-to-reaction mapping possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup - Import required libraries and initialize Spark\nfrom spark.utils import get_spark_session\nimport time\nimport pandas as pd\nfrom IPython.display import display\n\nspark = get_spark_session()\nnamespace = 'ontology_data'\n\n# Helper function to time queries\ndef time_query(query_name, query_func):\n    \"\"\"Execute a query and print execution time\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"Executing: {query_name}\")\n    print(f\"{'='*60}\")\n    start_time = time.time()\n    result = query_func()\n    end_time = time.time()\n    execution_time = end_time - start_time\n    print(f\"\\nQuery execution time: {execution_time:.2f} seconds\")\n    return result"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploring SEED Reactions in the Ontology\n",
    "\n",
    "SEED reactions are stored in the statements table with their labels. Let's see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def explore_seed_reactions():\n    query = f\"\"\"\n    SELECT \n        subject as reaction_id,\n        predicate,\n        value as reaction_name\n    FROM {namespace}.statements\n    WHERE subject LIKE 'seed.reaction:%'\n    AND predicate = 'rdfs:label'\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Sample SEED reactions from the ontology:\")\n    display(df)\n    \n    # Count total reactions\n    count_query = f\"\"\"\n    SELECT COUNT(DISTINCT subject) as total_reactions\n    FROM {namespace}.statements\n    WHERE subject LIKE 'seed.reaction:%'\n    AND predicate = 'rdfs:label'\n    \"\"\"\n    count = spark.sql(count_query).collect()[0]['total_reactions']\n    print(f\"\\nTotal SEED reactions in ontology: {count:,}\")\n\n# Execute without capturing return value to avoid duplicate display\ntime_query(\"Explore SEED Reactions\", explore_seed_reactions)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploring SEED Roles in the Ontology\n",
    "\n",
    "SEED roles represent enzyme functions. Let's examine them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def explore_seed_roles():\n    query = f\"\"\"\n    SELECT \n        subject as role_id,\n        predicate,\n        value as role_name\n    FROM {namespace}.statements\n    WHERE subject LIKE 'seed.role:%'\n    AND predicate = 'rdfs:label'\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Sample SEED roles (enzyme functions) from the ontology:\")\n    display(df)\n    \n    # Count total roles\n    count_query = f\"\"\"\n    SELECT COUNT(DISTINCT subject) as total_roles\n    FROM {namespace}.statements\n    WHERE subject LIKE 'seed.role:%'\n    AND predicate = 'rdfs:label'\n    \"\"\"\n    count = spark.sql(count_query).collect()[0]['total_roles']\n    print(f\"\\nTotal SEED roles in ontology: {count:,}\")\n\ntime_query(\"Explore SEED Roles\", explore_seed_roles)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Understanding Term Associations: How Roles Map to Reactions\n",
    "\n",
    "The term_association table connects SEED roles to reactions they catalyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def explore_term_associations():\n    query = f\"\"\"\n    WITH role_reaction_mappings AS (\n        SELECT \n            ta.subject as role_string,\n            ta.predicate,\n            ta.object as reaction_id\n        FROM {namespace}.term_association ta\n        WHERE ta.object LIKE 'seed.reaction:%'\n        AND ta.predicate = 'RO:0002327'\n        LIMIT 20\n    ),\n    enriched_mappings AS (\n        SELECT \n            m.role_string,\n            r.value as role_name,\n            m.reaction_id,\n            rxn.value as reaction_name,\n            m.predicate\n        FROM role_reaction_mappings m\n        LEFT JOIN {namespace}.statements r \n            ON m.role_string = r.subject AND r.predicate = 'rdfs:label'\n        LEFT JOIN {namespace}.statements rxn \n            ON m.reaction_id = rxn.subject AND rxn.predicate = 'rdfs:label'\n    )\n    SELECT * FROM enriched_mappings\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Sample role-to-reaction mappings:\")\n    display(df)\n    \n    # Show predicate meaning\n    print(\"\\nNote: predicate 'RO:0002327' means 'enables' - the role enables/catalyzes the reaction\")\n\ntime_query(\"Explore Term Associations\", explore_term_associations)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploring Feature Annotations: RAST Roles in Genomes\n",
    "\n",
    "The feature_annotation table contains RAST annotations that match SEED role names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def explore_feature_annotations():\n    query = f\"\"\"\n    SELECT \n        genome_id,\n        feature_id,\n        rast,\n        bakta_gene,\n        bakta_product\n    FROM {namespace}.feature_annotation\n    WHERE genome_id = '562.61239'\n    AND rast IS NOT NULL\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Sample RAST annotations from E. coli genome 562.61239:\")\n    display(df)\n    \n    # Count features with RAST annotations\n    count_query = f\"\"\"\n    SELECT \n        COUNT(*) as features_with_rast,\n        COUNT(DISTINCT rast) as unique_rast_roles\n    FROM {namespace}.feature_annotation\n    WHERE genome_id = '562.61239'\n    AND rast IS NOT NULL\n    \"\"\"\n    counts = spark.sql(count_query).collect()[0]\n    print(f\"\\nGenome 562.61239 has:\")\n    print(f\"  - {counts['features_with_rast']:,} features with RAST annotations\")\n    print(f\"  - {counts['unique_rast_roles']:,} unique RAST roles\")\n\ntime_query(\"Explore Feature Annotations\", explore_feature_annotations)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Connecting Features to Roles: The Key Link\n",
    "\n",
    "Let's verify that RAST annotations in feature_annotation match SEED role subjects in term_association:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def verify_rast_to_role_connection():\n    query = f\"\"\"\n    WITH genome_rast_roles AS (\n        -- Get unique RAST roles from our genome\n        SELECT DISTINCT rast\n        FROM {namespace}.feature_annotation\n        WHERE genome_id = '562.61239'\n        AND rast IS NOT NULL\n    ),\n    matching_term_associations AS (\n        -- Find which RAST roles exist in term_association\n        SELECT \n            gr.rast,\n            COUNT(DISTINCT ta.object) as reaction_count\n        FROM genome_rast_roles gr\n        INNER JOIN {namespace}.term_association ta\n            ON gr.rast = ta.subject\n        WHERE ta.object LIKE 'seed.reaction:%'\n        GROUP BY gr.rast\n    )\n    SELECT \n        rast as role_string,\n        reaction_count\n    FROM matching_term_associations\n    ORDER BY reaction_count DESC\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"RAST roles that successfully map to reactions:\")\n    display(df)\n    \n    # Summary statistics\n    stats_query = f\"\"\"\n    WITH genome_rast AS (\n        SELECT DISTINCT rast\n        FROM {namespace}.feature_annotation\n        WHERE genome_id = '562.61239'\n        AND rast IS NOT NULL\n    ),\n    mappable_rast AS (\n        SELECT DISTINCT gr.rast\n        FROM genome_rast gr\n        INNER JOIN {namespace}.term_association ta\n            ON gr.rast = ta.subject\n        WHERE ta.object LIKE 'seed.reaction:%'\n    )\n    SELECT \n        (SELECT COUNT(*) FROM genome_rast) as total_rast_roles,\n        (SELECT COUNT(*) FROM mappable_rast) as mappable_rast_roles\n    \"\"\"\n    stats = spark.sql(stats_query).collect()[0]\n    print(f\"\\nMapping success rate:\")\n    print(f\"  - Total unique RAST roles: {stats['total_rast_roles']}\")\n    print(f\"  - Roles that map to reactions: {stats['mappable_rast_roles']}\")\n    print(f\"  - Success rate: {stats['mappable_rast_roles']/stats['total_rast_roles']*100:.1f}%\")\n\ntime_query(\"Verify RAST to Role Connection\", verify_rast_to_role_connection)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Final Query 0: Genome Feature to Reaction Mapping\n",
    "\n",
    "Now let's put it all together - this is the complete query that maps genome features to reactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def query_genome_reactions():\n    query = f\"\"\"\n    WITH genome_features AS (\n        -- Step 1: Get features with RAST annotations from our genome\n        SELECT \n            f.genome_id,\n            f.feature_id,\n            f.rast\n        FROM {namespace}.feature_annotation f\n        WHERE f.genome_id = '562.61239'\n        AND f.rast IS NOT NULL\n    ),\n    feature_reactions AS (\n        -- Step 2: Map RAST roles to SEED reactions via term_association\n        SELECT DISTINCT\n            gf.genome_id,\n            gf.feature_id,\n            gf.rast,\n            ta.object as seed_reaction\n        FROM genome_features gf\n        INNER JOIN {namespace}.term_association ta\n            ON gf.rast = ta.subject  -- This is the key join!\n        WHERE ta.object LIKE 'seed.reaction:%'\n    ),\n    reaction_names AS (\n        -- Step 3: Get human-readable reaction names from statements\n        SELECT \n            subject as reaction_id,\n            value as reaction_name\n        FROM {namespace}.statements\n        WHERE predicate = 'rdfs:label'\n        AND subject LIKE 'seed.reaction:%'\n    )\n    -- Step 4: Combine everything\n    SELECT \n        fr.genome_id,\n        fr.feature_id,\n        fr.rast,\n        fr.seed_reaction,\n        rn.reaction_name\n    FROM feature_reactions fr\n    LEFT JOIN reaction_names rn ON fr.seed_reaction = rn.reaction_id\n    ORDER BY fr.genome_id, fr.feature_id\n    LIMIT 100\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Genome features mapped to their catalyzed reactions:\")\n    display(df.head(20))\n    print(f\"\\nTotal features with reaction mappings shown: {len(df)}\")\n\ntime_query(\"Complete Genome Feature to Reaction Mapping\", query_genome_reactions)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Extra Queries - Comparative Analysis of 50 E. coli Strains\n",
    "\n",
    "Now let's explore the diversity across all 50 E. coli genomes using multi-table queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Core vs Accessory Genes: What's Universal vs Strain-Specific?"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### 1. Core vs Accessory Genes: What's Universal vs Strain-Specific?\n\nThis query analyzes the pangenome structure by examining which genes (UniRef clusters) are shared across all 50 strains (core genes) versus those found in only some strains (accessory genes). Understanding the core genome helps identify essential functions for E. coli survival, while accessory genes reveal the evolutionary adaptations and niche-specific capabilities."
  },
  {
   "cell_type": "code",
   "source": "def analyze_core_accessory_genes():\n    query = f\"\"\"\n    WITH gene_distribution AS (\n        -- Count how many strains have each UniRef cluster\n        SELECT \n            uniref,\n            COUNT(DISTINCT genome_id) as strain_count,\n            ROUND(COUNT(DISTINCT genome_id) * 100.0 / 50, 1) as prevalence_pct\n        FROM {namespace}.feature_annotation\n        WHERE uniref IS NOT NULL\n        GROUP BY uniref\n    ),\n    gene_categories AS (\n        SELECT \n            CASE \n                WHEN strain_count = 50 THEN 'Core genes (100% strains)'\n                WHEN strain_count >= 48 THEN 'Soft-core genes (96-99% strains)'\n                WHEN strain_count >= 25 THEN 'Shell genes (50-95% strains)'\n                ELSE 'Cloud genes (<50% strains)'\n            END as gene_category,\n            COUNT(*) as gene_count\n        FROM gene_distribution\n        GROUP BY gene_category\n    )\n    SELECT * FROM gene_categories\n    ORDER BY \n        CASE gene_category\n            WHEN 'Core genes (100% strains)' THEN 1\n            WHEN 'Soft-core genes (96-99% strains)' THEN 2\n            WHEN 'Shell genes (50-95% strains)' THEN 3\n            ELSE 4\n        END\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Pangenome structure of 50 E. coli strains:\")\n    display(df)\n    \n    # Show examples of accessory genes\n    accessory_query = f\"\"\"\n    WITH gene_counts AS (\n        SELECT \n            f.uniref,\n            f.bakta_product,\n            COUNT(DISTINCT f.genome_id) as strain_count\n        FROM {namespace}.feature_annotation f\n        WHERE f.uniref IS NOT NULL\n        AND f.bakta_product IS NOT NULL\n        GROUP BY f.uniref, f.bakta_product\n    )\n    SELECT \n        uniref,\n        bakta_product,\n        strain_count,\n        ROUND(strain_count * 100.0 / 50, 1) as prevalence_pct\n    FROM gene_counts\n    WHERE strain_count BETWEEN 10 AND 40\n    ORDER BY strain_count DESC\n    LIMIT 15\n    \"\"\"\n    \n    accessory_df = spark.sql(accessory_query).toPandas()\n    print(f\"\\nExamples of accessory genes (present in 10-40 strains):\")\n    display(accessory_df)\n\ntime_query(\"Core vs Accessory Gene Analysis\", analyze_core_accessory_genes)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2. Functional Diversity: EC Number Distribution Across Strains\n\nThis query examines the distribution of enzyme commission (EC) numbers across strains to understand functional diversity. By categorizing enzymes as universal, conserved, or variable, we can identify which metabolic capabilities are essential versus those that provide strain-specific advantages."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def analyze_ec_diversity():\n    query = f\"\"\"\n    WITH strain_ec_profiles AS (\n        -- Get EC number profiles for each strain\n        SELECT \n            f.genome_id,\n            f.bakta_ec,\n            s.value as ec_name\n        FROM {namespace}.feature_annotation f\n        LEFT JOIN {namespace}.statements s\n            ON CONCAT('EC:', f.bakta_ec) = s.subject\n            AND s.predicate = 'rdfs:label'\n        WHERE f.bakta_ec IS NOT NULL\n    ),\n    ec_distribution AS (\n        -- Count how many strains have each EC number\n        SELECT \n            bakta_ec,\n            MAX(ec_name) as ec_name,\n            COUNT(DISTINCT genome_id) as strain_count,\n            ROUND(COUNT(DISTINCT genome_id) * 100.0 / 50, 1) as prevalence_pct\n        FROM strain_ec_profiles\n        GROUP BY bakta_ec\n    ),\n    categorized_ec AS (\n        SELECT \n            *,\n            CASE \n                WHEN strain_count = 50 THEN 'Universal'\n                WHEN strain_count >= 40 THEN 'Highly conserved'\n                WHEN strain_count >= 25 THEN 'Common'\n                WHEN strain_count >= 10 THEN 'Variable'\n                ELSE 'Rare'\n            END as conservation_category\n        FROM ec_distribution\n    )\n    SELECT \n        conservation_category,\n        COUNT(*) as ec_count,\n        MIN(strain_count) as min_strains,\n        MAX(strain_count) as max_strains,\n        ROUND(AVG(prevalence_pct), 1) as avg_prevalence_pct\n    FROM categorized_ec\n    GROUP BY conservation_category\n    ORDER BY max_strains DESC\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"EC number conservation across 50 E. coli strains:\")\n    display(df)\n    \n    # Show variable EC functions\n    variable_ec_query = f\"\"\"\n    WITH ec_counts AS (\n        SELECT \n            f.bakta_ec,\n            s.value as ec_name,\n            COUNT(DISTINCT f.genome_id) as strain_count\n        FROM {namespace}.feature_annotation f\n        LEFT JOIN {namespace}.statements s\n            ON CONCAT('EC:', f.bakta_ec) = s.subject\n            AND s.predicate = 'rdfs:label'\n        WHERE f.bakta_ec IS NOT NULL\n        GROUP BY f.bakta_ec, s.value\n    )\n    SELECT * FROM ec_counts\n    WHERE strain_count BETWEEN 10 AND 40\n    ORDER BY strain_count DESC\n    LIMIT 15\n    \"\"\"\n    \n    variable_df = spark.sql(variable_ec_query).toPandas()\n    print(f\"\\nVariable enzymatic functions (present in 10-40 strains):\")\n    display(variable_df)\n\ntime_query(\"EC Number Diversity Analysis\", analyze_ec_diversity)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3. Metabolic Capability Differences: Reaction Sets Between Strains\n\nThis query compares the total number of metabolic reactions each strain can perform by mapping RAST annotations to SEED reactions. Strains with more reactions have broader metabolic capabilities, potentially allowing them to thrive in more diverse environments or utilize a wider range of nutrients."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compare_metabolic_capabilities():\n    query = f\"\"\"\n    WITH strain_reactions AS (\n        -- Map each strain to its set of reactions\n        SELECT DISTINCT\n            f.genome_id,\n            ta.object as reaction_id\n        FROM {namespace}.feature_annotation f\n        INNER JOIN {namespace}.term_association ta\n            ON f.rast = ta.subject\n        WHERE f.rast IS NOT NULL\n        AND ta.object LIKE 'seed.reaction:%'\n    ),\n    strain_reaction_counts AS (\n        -- Count reactions per strain\n        SELECT \n            genome_id,\n            COUNT(DISTINCT reaction_id) as reaction_count\n        FROM strain_reactions\n        GROUP BY genome_id\n    ),\n    reaction_distribution AS (\n        -- See how reactions are distributed\n        SELECT \n            reaction_id,\n            COUNT(DISTINCT genome_id) as strain_count\n        FROM strain_reactions\n        GROUP BY reaction_id\n    ),\n    stats AS (\n        SELECT \n            MIN(reaction_count) as min_reactions,\n            MAX(reaction_count) as max_reactions,\n            AVG(reaction_count) as avg_reactions,\n            STDDEV(reaction_count) as std_reactions\n        FROM strain_reaction_counts\n    )\n    SELECT \n        'Metabolic Capacity Statistics' as metric,\n        min_reactions,\n        max_reactions,\n        ROUND(avg_reactions, 1) as avg_reactions,\n        ROUND(std_reactions, 1) as std_reactions,\n        max_reactions - min_reactions as reaction_range\n    FROM stats\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Metabolic reaction capacity across strains:\")\n    display(df)\n    \n    # Show strains with extreme metabolic capacities\n    extremes_query = f\"\"\"\n    WITH strain_reactions AS (\n        SELECT DISTINCT\n            f.genome_id,\n            ta.object as reaction_id\n        FROM {namespace}.feature_annotation f\n        INNER JOIN {namespace}.term_association ta\n            ON f.rast = ta.subject\n        WHERE f.rast IS NOT NULL\n        AND ta.object LIKE 'seed.reaction:%'\n    ),\n    strain_counts AS (\n        SELECT \n            sr.genome_id,\n            COUNT(DISTINCT sr.reaction_id) as reaction_count,\n            MAX(s.value) as organism_name\n        FROM strain_reactions sr\n        LEFT JOIN {namespace}.feature_annotation fa ON sr.genome_id = fa.genome_id\n        LEFT JOIN {namespace}.statements s \n            ON fa.genome_taxa = s.subject AND s.predicate = 'rdfs:label'\n        GROUP BY sr.genome_id\n    )\n    (\n        SELECT *, 'Highest capacity' as category\n        FROM strain_counts\n        ORDER BY reaction_count DESC\n        LIMIT 5\n    )\n    UNION ALL\n    (\n        SELECT *, 'Lowest capacity' as category\n        FROM strain_counts\n        ORDER BY reaction_count ASC\n        LIMIT 5\n    )\n    ORDER BY category, reaction_count DESC\n    \"\"\"\n    \n    extremes_df = spark.sql(extremes_query).toPandas()\n    print(f\"\\nStrains with extreme metabolic capacities:\")\n    display(extremes_df)\n\ntime_query(\"Metabolic Capability Comparison\", compare_metabolic_capabilities)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4. Taxonomic Clustering by Functional Profiles\n\nThis query profiles each strain by its enzyme class distribution (oxidoreductases, transferases, etc.) to identify functional similarities. Strains with similar enzyme profiles likely have similar metabolic capabilities and may occupy similar ecological niches."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def analyze_taxonomic_functional_clusters():\n    query = f\"\"\"\n    WITH strain_taxonomy AS (\n        -- Get taxonomic info for each strain\n        SELECT DISTINCT\n            f.genome_id,\n            f.genome_taxa,\n            s.value as strain_name\n        FROM {namespace}.feature_annotation f\n        LEFT JOIN {namespace}.statements s\n            ON f.genome_taxa = s.subject AND s.predicate = 'rdfs:label'\n    ),\n    strain_functions AS (\n        -- Get functional profile (EC numbers) for each strain\n        SELECT \n            genome_id,\n            COUNT(DISTINCT bakta_ec) as ec_count,\n            COUNT(DISTINCT bakta_go) as go_count,\n            COUNT(DISTINCT CASE WHEN bakta_ec LIKE '1.%' THEN bakta_ec END) as oxidoreductases,\n            COUNT(DISTINCT CASE WHEN bakta_ec LIKE '2.%' THEN bakta_ec END) as transferases,\n            COUNT(DISTINCT CASE WHEN bakta_ec LIKE '3.%' THEN bakta_ec END) as hydrolases,\n            COUNT(DISTINCT CASE WHEN bakta_ec LIKE '4.%' THEN bakta_ec END) as lyases,\n            COUNT(DISTINCT CASE WHEN bakta_ec LIKE '5.%' THEN bakta_ec END) as isomerases,\n            COUNT(DISTINCT CASE WHEN bakta_ec LIKE '6.%' THEN bakta_ec END) as ligases\n        FROM {namespace}.feature_annotation\n        WHERE bakta_ec IS NOT NULL\n        GROUP BY genome_id\n    )\n    SELECT \n        st.genome_id,\n        st.strain_name,\n        sf.ec_count,\n        sf.go_count,\n        sf.oxidoreductases,\n        sf.transferases,\n        sf.hydrolases,\n        sf.lyases,\n        sf.isomerases,\n        sf.ligases,\n        ROUND(sf.transferases * 100.0 / sf.ec_count, 1) as transferase_pct,\n        ROUND(sf.hydrolases * 100.0 / sf.ec_count, 1) as hydrolase_pct\n    FROM strain_taxonomy st\n    JOIN strain_functions sf ON st.genome_id = sf.genome_id\n    ORDER BY sf.ec_count DESC\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Functional enzyme profiles by strain:\")\n    display(df)\n\ntime_query(\"Taxonomic-Functional Clustering\", analyze_taxonomic_functional_clusters)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5. Pathway Completeness Analysis\n\nThis query evaluates the completeness of essential metabolic pathways (using glycolysis as an example) across strains. Complete pathways indicate robust metabolic capabilities, while missing reactions might represent alternative pathways or adaptations to specific environments."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def analyze_pathway_completeness():\n    query = f\"\"\"\n    WITH glycolysis_reactions AS (\n        -- Define key glycolysis reactions (example pathway)\n        SELECT reaction_id, reaction_name FROM (\n            VALUES \n            ('seed.reaction:rxn00558', 'Glucose-6-phosphate isomerase'),\n            ('seed.reaction:rxn00604', 'Phosphofructokinase'),\n            ('seed.reaction:rxn00711', 'Fructose-bisphosphate aldolase'),\n            ('seed.reaction:rxn00024', 'Glyceraldehyde-3-phosphate dehydrogenase'),\n            ('seed.reaction:rxn00083', 'Phosphoglycerate kinase'),\n            ('seed.reaction:rxn00119', 'Phosphoglycerate mutase'),\n            ('seed.reaction:rxn00094', 'Enolase'),\n            ('seed.reaction:rxn00200', 'Pyruvate kinase')\n        ) AS t(reaction_id, reaction_name)\n    ),\n    strain_glycolysis_coverage AS (\n        -- Check which strains have which glycolysis reactions\n        SELECT \n            f.genome_id,\n            COUNT(DISTINCT gr.reaction_id) as glycolysis_reactions_present,\n            8 as total_glycolysis_reactions,\n            ROUND(COUNT(DISTINCT gr.reaction_id) * 100.0 / 8, 1) as pathway_completeness_pct\n        FROM {namespace}.feature_annotation f\n        INNER JOIN {namespace}.term_association ta ON f.rast = ta.subject\n        INNER JOIN glycolysis_reactions gr ON ta.object = gr.reaction_id\n        WHERE f.rast IS NOT NULL\n        GROUP BY f.genome_id\n    ),\n    completeness_summary AS (\n        SELECT \n            CASE \n                WHEN pathway_completeness_pct = 100 THEN 'Complete'\n                WHEN pathway_completeness_pct >= 75 THEN 'Nearly complete'\n                WHEN pathway_completeness_pct >= 50 THEN 'Partial'\n                ELSE 'Incomplete'\n            END as completeness_category,\n            COUNT(*) as strain_count\n        FROM strain_glycolysis_coverage\n        GROUP BY completeness_category\n    )\n    SELECT * FROM completeness_summary\n    ORDER BY \n        CASE completeness_category\n            WHEN 'Complete' THEN 1\n            WHEN 'Nearly complete' THEN 2\n            WHEN 'Partial' THEN 3\n            ELSE 4\n        END\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Glycolysis pathway completeness across strains:\")\n    display(df)\n    \n    # Show which reactions are most commonly missing\n    missing_reactions_query = f\"\"\"\n    WITH glycolysis_reactions AS (\n        SELECT reaction_id, reaction_name FROM (\n            VALUES \n            ('seed.reaction:rxn00558', 'Glucose-6-phosphate isomerase'),\n            ('seed.reaction:rxn00604', 'Phosphofructokinase'),\n            ('seed.reaction:rxn00711', 'Fructose-bisphosphate aldolase'),\n            ('seed.reaction:rxn00024', 'Glyceraldehyde-3-phosphate dehydrogenase'),\n            ('seed.reaction:rxn00083', 'Phosphoglycerate kinase'),\n            ('seed.reaction:rxn00119', 'Phosphoglycerate mutase'),\n            ('seed.reaction:rxn00094', 'Enolase'),\n            ('seed.reaction:rxn00200', 'Pyruvate kinase')\n        ) AS t(reaction_id, reaction_name)\n    ),\n    reaction_presence AS (\n        SELECT \n            gr.reaction_id,\n            gr.reaction_name,\n            COUNT(DISTINCT f.genome_id) as strains_with_reaction\n        FROM glycolysis_reactions gr\n        LEFT JOIN {namespace}.term_association ta ON gr.reaction_id = ta.object\n        LEFT JOIN {namespace}.feature_annotation f \n            ON ta.subject = f.rast AND f.rast IS NOT NULL\n        GROUP BY gr.reaction_id, gr.reaction_name\n    )\n    SELECT \n        reaction_name,\n        strains_with_reaction,\n        50 - strains_with_reaction as strains_missing_reaction,\n        ROUND(strains_with_reaction * 100.0 / 50, 1) as presence_pct\n    FROM reaction_presence\n    ORDER BY strains_with_reaction DESC\n    \"\"\"\n    \n    missing_df = spark.sql(missing_reactions_query).toPandas()\n    print(f\"\\nGlycolysis reaction presence across 50 strains:\")\n    display(missing_df)\n\ntime_query(\"Pathway Completeness Analysis\", analyze_pathway_completeness)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6. Unique Functional Features by Strain\n\nThis query identifies functions (RAST roles) that are unique to individual strains, revealing strain-specific metabolic capabilities. These unique features may represent recent acquisitions through horizontal gene transfer or specialized adaptations to particular environments."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def find_unique_strain_features():\n    query = f\"\"\"\n    WITH feature_distribution AS (\n        -- Find features unique to single strains\n        SELECT \n            rast,\n            COUNT(DISTINCT genome_id) as strain_count,\n            COLLECT_SET(genome_id)[0] as unique_to_genome\n        FROM {namespace}.feature_annotation\n        WHERE rast IS NOT NULL\n        GROUP BY rast\n        HAVING COUNT(DISTINCT genome_id) = 1\n    ),\n    unique_features_with_reactions AS (\n        -- See if these unique features have known reactions\n        SELECT \n            fd.unique_to_genome,\n            fd.rast,\n            ta.object as reaction_id,\n            s1.value as reaction_name,\n            s2.value as strain_name\n        FROM feature_distribution fd\n        LEFT JOIN {namespace}.term_association ta ON fd.rast = ta.subject\n        LEFT JOIN {namespace}.statements s1 \n            ON ta.object = s1.subject AND s1.predicate = 'rdfs:label'\n        LEFT JOIN {namespace}.feature_annotation fa ON fd.unique_to_genome = fa.genome_id\n        LEFT JOIN {namespace}.statements s2 \n            ON fa.genome_taxa = s2.subject AND s2.predicate = 'rdfs:label'\n        WHERE ta.object LIKE 'seed.reaction:%'\n    ),\n    strain_unique_counts AS (\n        SELECT \n            unique_to_genome,\n            MAX(strain_name) as strain_name,\n            COUNT(DISTINCT rast) as unique_functions,\n            COUNT(DISTINCT reaction_id) as unique_reactions\n        FROM unique_features_with_reactions\n        GROUP BY unique_to_genome\n    )\n    SELECT * FROM strain_unique_counts\n    WHERE unique_reactions > 0\n    ORDER BY unique_reactions DESC\n    LIMIT 15\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Strains with unique metabolic capabilities:\")\n    display(df)\n    \n    # Show examples of unique functions\n    examples_query = f\"\"\"\n    WITH unique_features AS (\n        SELECT \n            rast,\n            COLLECT_SET(genome_id)[0] as genome_id\n        FROM {namespace}.feature_annotation\n        WHERE rast IS NOT NULL\n        GROUP BY rast\n        HAVING COUNT(DISTINCT genome_id) = 1\n    )\n    SELECT \n        uf.genome_id,\n        uf.rast as unique_function,\n        ta.object as reaction_id,\n        s.value as reaction_name\n    FROM unique_features uf\n    INNER JOIN {namespace}.term_association ta ON uf.rast = ta.subject\n    LEFT JOIN {namespace}.statements s \n        ON ta.object = s.subject AND s.predicate = 'rdfs:label'\n    WHERE ta.object LIKE 'seed.reaction:%'\n    LIMIT 10\n    \"\"\"\n    \n    examples_df = spark.sql(examples_query).toPandas()\n    print(f\"\\nExamples of strain-specific functions and reactions:\")\n    display(examples_df)\n\ntime_query(\"Unique Strain Features Analysis\", find_unique_strain_features)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 7. Conservation Analysis: Most and Least Conserved Functions\n\nThis query analyzes GO term conservation to identify molecular functions that are universally conserved versus those that are rare. Highly conserved functions represent the core cellular machinery, while rarely conserved functions may indicate specialized adaptations or recent evolutionary innovations."
  },
  {
   "cell_type": "markdown",
   "source": "### 8. GO Term Hierarchy Analysis\n\nThis query explores the parent-child relationships in GO ontology by analyzing which GO terms have the most children and how deep the hierarchy goes. Understanding GO hierarchy helps reveal functional specialization patterns and the granularity of annotations across strains.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def analyze_go_hierarchy():\n    query = f\"\"\"\n    WITH go_relationships AS (\n        -- Get parent-child relationships from statements\n        SELECT \n            s1.subject as child_go,\n            s1.object as parent_go,\n            s2.value as child_name,\n            s3.value as parent_name\n        FROM {namespace}.statements s1\n        LEFT JOIN {namespace}.statements s2 \n            ON s1.subject = s2.subject AND s2.predicate = 'rdfs:label'\n        LEFT JOIN {namespace}.statements s3 \n            ON s1.object = s3.subject AND s3.predicate = 'rdfs:label'\n        WHERE s1.predicate = 'rdfs:subClassOf'\n        AND s1.subject LIKE 'GO:%'\n        AND s1.object LIKE 'GO:%'\n    ),\n    parent_child_counts AS (\n        -- Count children for each parent GO term\n        SELECT \n            parent_go,\n            MAX(parent_name) as parent_name,\n            COUNT(DISTINCT child_go) as child_count\n        FROM go_relationships\n        GROUP BY parent_go\n    ),\n    go_in_annotations AS (\n        -- Find which GO terms are actually used in our annotations\n        SELECT DISTINCT bakta_go as go_term\n        FROM {namespace}.feature_annotation\n        WHERE bakta_go IS NOT NULL\n    )\n    SELECT \n        pcc.parent_go,\n        pcc.parent_name,\n        pcc.child_count,\n        CASE WHEN gia.go_term IS NOT NULL THEN 'Used in annotations' ELSE 'Not used' END as usage_status\n    FROM parent_child_counts pcc\n    LEFT JOIN go_in_annotations gia ON pcc.parent_go = gia.go_term\n    WHERE pcc.child_count >= 10\n    ORDER BY pcc.child_count DESC\n    LIMIT 20\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"GO terms with the most children in the hierarchy:\")\n    display(df)\n    \n    # Analyze depth of GO terms used in annotations\n    depth_query = f\"\"\"\n    WITH RECURSIVE go_depth AS (\n        -- Base case: root GO terms (no parents)\n        SELECT \n            subject as go_term,\n            0 as depth\n        FROM {namespace}.statements\n        WHERE subject LIKE 'GO:%'\n        AND subject NOT IN (\n            SELECT subject \n            FROM {namespace}.statements \n            WHERE predicate = 'rdfs:subClassOf' \n            AND object LIKE 'GO:%'\n        )\n        \n        UNION ALL\n        \n        -- Recursive case: children of current level\n        SELECT \n            s.subject as go_term,\n            gd.depth + 1 as depth\n        FROM {namespace}.statements s\n        JOIN go_depth gd ON s.object = gd.go_term\n        WHERE s.predicate = 'rdfs:subClassOf'\n        AND s.subject LIKE 'GO:%'\n    ),\n    annotated_go_depth AS (\n        SELECT \n            f.bakta_go,\n            MAX(gd.depth) as max_depth\n        FROM {namespace}.feature_annotation f\n        JOIN go_depth gd ON f.bakta_go = gd.go_term\n        WHERE f.bakta_go IS NOT NULL\n        GROUP BY f.bakta_go\n    )\n    SELECT \n        CASE \n            WHEN max_depth <= 3 THEN 'Shallow (0-3 levels)'\n            WHEN max_depth <= 6 THEN 'Medium (4-6 levels)'\n            WHEN max_depth <= 9 THEN 'Deep (7-9 levels)'\n            ELSE 'Very deep (10+ levels)'\n        END as depth_category,\n        COUNT(*) as go_term_count,\n        AVG(max_depth) as avg_depth\n    FROM annotated_go_depth\n    GROUP BY depth_category\n    ORDER BY avg_depth\n    \"\"\"\n    \n    # Note: Recursive queries might not be supported, so let's use a simpler approach\n    simple_depth_query = f\"\"\"\n    WITH go_with_parents AS (\n        SELECT \n            f.bakta_go,\n            COUNT(DISTINCT s.object) as parent_count\n        FROM {namespace}.feature_annotation f\n        LEFT JOIN {namespace}.statements s \n            ON f.bakta_go = s.subject \n            AND s.predicate = 'rdfs:subClassOf'\n            AND s.object LIKE 'GO:%'\n        WHERE f.bakta_go IS NOT NULL\n        GROUP BY f.bakta_go\n    )\n    SELECT \n        CASE \n            WHEN parent_count = 0 THEN 'Root terms'\n            WHEN parent_count = 1 THEN 'Single parent'\n            WHEN parent_count = 2 THEN 'Two parents'\n            ELSE 'Multiple parents (3+)'\n        END as hierarchy_type,\n        COUNT(*) as go_term_count\n    FROM go_with_parents\n    GROUP BY hierarchy_type\n    ORDER BY go_term_count DESC\n    \"\"\"\n    \n    hierarchy_df = spark.sql(simple_depth_query).toPandas()\n    print(f\"\\nGO term hierarchy patterns in annotations:\")\n    display(hierarchy_df)\n\ntime_query(\"GO Term Hierarchy Analysis\", analyze_go_hierarchy)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 9. GO Enrichment by Strain\n\nThis query identifies strain-specific GO term enrichments by comparing the frequency of GO terms in individual strains against the background frequency across all strains. This reveals which biological functions are over-represented in specific strains, suggesting adaptations or specializations.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def analyze_go_enrichment_by_strain():\n    query = f\"\"\"\n    WITH strain_go_counts AS (\n        -- Count GO terms per strain\n        SELECT \n            f.genome_id,\n            f.bakta_go,\n            s.value as go_name,\n            COUNT(*) as count_in_strain\n        FROM {namespace}.feature_annotation f\n        LEFT JOIN {namespace}.statements s \n            ON f.bakta_go = s.subject AND s.predicate = 'rdfs:label'\n        WHERE f.bakta_go IS NOT NULL\n        GROUP BY f.genome_id, f.bakta_go, s.value\n    ),\n    global_go_counts AS (\n        -- Count GO terms across all strains\n        SELECT \n            bakta_go,\n            COUNT(*) as global_count,\n            COUNT(DISTINCT genome_id) as strains_with_term\n        FROM {namespace}.feature_annotation\n        WHERE bakta_go IS NOT NULL\n        GROUP BY bakta_go\n    ),\n    strain_totals AS (\n        -- Total annotations per strain\n        SELECT \n            genome_id,\n            COUNT(*) as total_annotations\n        FROM {namespace}.feature_annotation\n        WHERE bakta_go IS NOT NULL\n        GROUP BY genome_id\n    ),\n    enrichment_analysis AS (\n        SELECT \n            sgc.genome_id,\n            sgc.bakta_go,\n            sgc.go_name,\n            sgc.count_in_strain,\n            st.total_annotations as strain_total,\n            ggc.global_count,\n            ggc.strains_with_term,\n            -- Calculate enrichment ratio\n            (sgc.count_in_strain * 1.0 / st.total_annotations) / \n            (ggc.global_count * 1.0 / (SELECT SUM(total_annotations) FROM strain_totals)) as enrichment_ratio\n        FROM strain_go_counts sgc\n        JOIN global_go_counts ggc ON sgc.bakta_go = ggc.bakta_go\n        JOIN strain_totals st ON sgc.genome_id = st.genome_id\n        WHERE ggc.strains_with_term >= 10  -- Only consider GO terms in at least 10 strains\n    ),\n    top_enrichments AS (\n        SELECT *\n        FROM enrichment_analysis\n        WHERE enrichment_ratio > 2.0  -- At least 2-fold enrichment\n        AND count_in_strain >= 5      -- At least 5 occurrences in the strain\n    )\n    SELECT \n        genome_id,\n        COUNT(DISTINCT bakta_go) as enriched_go_terms,\n        AVG(enrichment_ratio) as avg_enrichment_ratio,\n        MAX(enrichment_ratio) as max_enrichment_ratio\n    FROM top_enrichments\n    GROUP BY genome_id\n    ORDER BY enriched_go_terms DESC\n    LIMIT 15\n    \"\"\"\n    \n    df = spark.sql(query).toPandas()\n    print(f\"Strains with the most enriched GO terms:\")\n    display(df)\n    \n    # Show specific enriched GO terms for top strains\n    specific_enrichments_query = f\"\"\"\n    WITH strain_go_counts AS (\n        SELECT \n            f.genome_id,\n            f.bakta_go,\n            s.value as go_name,\n            COUNT(*) as count_in_strain\n        FROM {namespace}.feature_annotation f\n        LEFT JOIN {namespace}.statements s \n            ON f.bakta_go = s.subject AND s.predicate = 'rdfs:label'\n        WHERE f.bakta_go IS NOT NULL\n        GROUP BY f.genome_id, f.bakta_go, s.value\n    ),\n    global_go_counts AS (\n        SELECT \n            bakta_go,\n            COUNT(*) as global_count,\n            COUNT(DISTINCT genome_id) as strains_with_term\n        FROM {namespace}.feature_annotation\n        WHERE bakta_go IS NOT NULL\n        GROUP BY bakta_go\n    ),\n    strain_totals AS (\n        SELECT \n            genome_id,\n            COUNT(*) as total_annotations\n        FROM {namespace}.feature_annotation\n        WHERE bakta_go IS NOT NULL\n        GROUP BY genome_id\n    ),\n    enrichment_details AS (\n        SELECT \n            sgc.genome_id,\n            sgc.bakta_go,\n            sgc.go_name,\n            sgc.count_in_strain,\n            ggc.strains_with_term,\n            (sgc.count_in_strain * 1.0 / st.total_annotations) / \n            (ggc.global_count * 1.0 / (SELECT SUM(total_annotations) FROM strain_totals)) as enrichment_ratio\n        FROM strain_go_counts sgc\n        JOIN global_go_counts ggc ON sgc.bakta_go = ggc.bakta_go\n        JOIN strain_totals st ON sgc.genome_id = st.genome_id\n        WHERE sgc.genome_id IN ('562.61119', '562.61097', '562.55859')  -- Top metabolic capacity strains\n        AND ggc.strains_with_term >= 10\n        AND sgc.count_in_strain >= 5\n    )\n    SELECT \n        genome_id,\n        bakta_go,\n        go_name,\n        count_in_strain,\n        strains_with_term,\n        ROUND(enrichment_ratio, 2) as enrichment_ratio\n    FROM enrichment_details\n    WHERE enrichment_ratio > 1.5\n    ORDER BY genome_id, enrichment_ratio DESC\n    LIMIT 20\n    \"\"\"\n    \n    specific_df = spark.sql(specific_enrichments_query).toPandas()\n    print(f\"\\nSpecific enriched GO terms in high-capacity strains:\")\n    display(specific_df)\n\ntime_query(\"GO Enrichment by Strain Analysis\", analyze_go_enrichment_by_strain)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Building blocks of Query 0**: How SEED reactions, roles, term associations, and feature annotations connect to map genome features to metabolic reactions\n",
    "\n",
    "2. **Comparative genomics insights**: Analysis of 50 E. coli strains revealed:\n",
    "   - Core vs accessory genome structure\n",
    "   - Functional diversity in enzymatic capabilities\n",
    "   - Metabolic capacity variations\n",
    "   - Pathway completeness patterns\n",
    "   - Strain-specific unique features\n",
    "   - Conservation patterns of molecular functions\n",
    "\n",
    "These queries showcase the power of integrating ontology data with genomic annotations to understand bacterial diversity and evolution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}